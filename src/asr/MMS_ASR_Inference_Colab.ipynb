{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishav-eulb/ai-tools/blob/rishav-eulb-patch-3/src/asr/MMS_ASR_Inference_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running MMS-ASR inference in Colab"
      ],
      "metadata": {
        "id": "Rhm7khm6GskV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will give an example on how to run simple ASR inference using MMS ASR model. \n",
        "\n",
        "Credit to epk2112 [(github)](https://github.com/epk2112/fairseq_meta_mms_Google_Colab_implementation)"
      ],
      "metadata": {
        "id": "83HXBIFeJzR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone fairseq-py and install latest version"
      ],
      "metadata": {
        "id": "2GfxksHDGyJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj2x80SegRzr",
        "outputId": "fdcf488d-914f-4687-e2aa-2adc01e2d80f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 34697, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 34697 (delta 73), reused 124 (delta 53), pack-reused 34543\u001b[K\n",
            "Receiving objects: 100% (34697/34697), 24.76 MiB | 5.98 MiB/s, done.\n",
            "Resolving deltas: 100% (25174/25174), done.\n",
            "/content\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq==0.12.2)\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq==0.12.2)\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.22.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq==0.12.2)\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (4.65.0)\n",
            "Collecting bitarray (from fairseq==0.12.2)\n",
            "  Downloading bitarray-2.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.7/272.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (2.0.2+cu118)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fairseq==0.12.2) (23.1)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.1->fairseq==0.12.2) (4.5.0)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq==0.12.2)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (4.9.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->fairseq==0.12.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13->fairseq==0.12.2) (16.0.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq==0.12.2) (2.21)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fairseq==0.12.2) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime\n",
            "  Building editable for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9219 sha256=2a9b350555c8f5ecb7601e9b126b92fd462d60bf69790d9d6ffd3bd38ab88868\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uo3y6kxa/wheels/c6/d7/db/bc419b1daa8266aa8de2a7c4d29f62dbfa814e8701fe4695a2\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=dd76db4c4830d7a0d308371c0e6889845e8743fcd7ad7270bbe2109c175062b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "Successfully built fairseq antlr4-python3-runtime\n",
            "Installing collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, colorama, sacrebleu, hydra-core, fairseq\n",
            "Successfully installed antlr4-python3-runtime-4.8 bitarray-2.7.3 colorama-0.4.6 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.7.0 sacrebleu-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ],
      "source": [
        "!mkdir \"temp_dir\"\n",
        "!git clone https://github.com/pytorch/fairseq\n",
        "\n",
        "# Change current working directory\n",
        "!pwd\n",
        "%cd \"/content/fairseq\"\n",
        "!pip install --editable ./ \n",
        "!pip install tensorboardX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download MMS model\n",
        "Un-comment to download your preferred model.\n",
        "In this example, we use MMS-FL102 for demo purposes.\n",
        "For better model quality and language coverage, user can use MMS-1B-ALL model instead (but it would require more RAM, so please use Colab-Pro instead of Colab-Free).\n"
      ],
      "metadata": {
        "id": "cyk4JvZOHSw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MMS-1B:FL102 model - 102 Languages - FLEURS Dataset\n",
        "!wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt'\n",
        "\n",
        "# # MMS-1B:L1107 - 1107 Languages - MMS-lab Dataset\n",
        "# !wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_l1107.pt'\n",
        "\n",
        "# # MMS-1B-all - 1162 Languages - MMS-lab + FLEURS + CV + VP + MLS\n",
        "# !wget -P ./models_new 'https://dl.fbaipublicfiles.com/mms/asr/mms1b_all.pt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uZ9WG85gZId",
        "outputId": "91f0527b-391e-402d-eb48-eb267bb0d399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-29 00:53:31--  https://dl.fbaipublicfiles.com/mms/asr/mms1b_fl102.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.227.219.10, 13.227.219.70, 13.227.219.33, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.227.219.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4851043301 (4.5G) [binary/octet-stream]\n",
            "Saving to: ‘./models_new/mms1b_fl102.pt’\n",
            "\n",
            "mms1b_fl102.pt      100%[===================>]   4.52G  84.1MB/s    in 24s     \n",
            "\n",
            "2023-05-29 00:53:56 (190 MB/s) - ‘./models_new/mms1b_fl102.pt’ saved [4851043301/4851043301]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare audio file\n",
        "Create a folder on path '/content/audio_samples/' and upload your .wav audio files that you need to transcribe e.g. '/content/audio_samples/audio.wav' \n",
        "\n",
        "Note: You need to make sure that the audio data you are using has a sample rate of 16kHz You can easily do this with FFMPEG like the example below that converts .mp3 file to .wav and fixing the audio sample rate\n",
        "\n",
        "Here, we use a FLEURS english MP3 audio for the example."
      ],
      "metadata": {
        "id": "3p5-TQvKHXjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/audio_samples \n",
        "!ffmpeg -y -i /content/audio_samples/audio_18.mp3 -ar 16000 /content/audio_samples/audio_18.wav"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnim4bokprbB",
        "outputId": "5c08dbaf-a14a-4bb2-ff0f-0a157699a8be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wget: missing URL\n",
            "Usage: wget [OPTION]... [URL]...\n",
            "\n",
            "Try `wget --help' for more options.\n",
            "ffmpeg version 4.2.7-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n",
            "  built with gcc 9 (Ubuntu 9.4.0-1ubuntu1~20.04.1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-avresample --disable-filter=resample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librsvg --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-nvenc --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 31.100 / 56. 31.100\n",
            "  libavcodec     58. 54.100 / 58. 54.100\n",
            "  libavformat    58. 29.100 / 58. 29.100\n",
            "  libavdevice    58.  8.100 / 58.  8.100\n",
            "  libavfilter     7. 57.100 /  7. 57.100\n",
            "  libavresample   4.  0.  0 /  4.  0.  0\n",
            "  libswscale      5.  5.100 /  5.  5.100\n",
            "  libswresample   3.  5.100 /  3.  5.100\n",
            "  libpostproc    55.  5.100 / 55.  5.100\n",
            "Input #0, mp3, from '/content/audio_samples/audio_18.mp3':\n",
            "  Duration: 00:00:42.05, start: 0.138125, bitrate: 34 kb/s\n",
            "    Stream #0:0: Audio: mp3, 8000 Hz, mono, fltp, 34 kb/s\n",
            "    Metadata:\n",
            "      encoder         : LAME3.100\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/audio_samples/audio_18.wav':\n",
            "  Metadata:\n",
            "    ISFT            : Lavf58.29.100\n",
            "    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.54.100 pcm_s16le\n",
            "size=    1309kB time=00:00:41.88 bitrate= 256.0kbits/s speed=1.97e+03x    \n",
            "video:0kB audio:1309kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.005819%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: Run Inference and transcribe your audio(s)\n"
      ],
      "metadata": {
        "id": "44UvHjmMI28Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the below example, we will transcribe a sentence in English.\n",
        "\n",
        "To transcribe other languages: \n",
        "1. Go to [MMS README ASR section](https://github.com/facebookresearch/fairseq/tree/main/examples/mms#asr)\n",
        "2. Open Supported languages link\n",
        "3. Find your target languages based on Language Name column\n",
        "4. Copy the corresponding Iso Code\n",
        "5. Replace `--lang \"eng\"` with new Iso Code\n",
        "\n",
        "To improve the transcription quality, user can use language-model (LM) decoding by following this instruction [ASR LM decoding](https://github.com/facebookresearch/fairseq/tree/main/examples/mms#asr)"
      ],
      "metadata": {
        "id": "82Xpxot2wFid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TMPDIR\"] = '/content/temp_dir'\n",
        "os.environ[\"PYTHONPATH\"] = \".\"\n",
        "os.environ[\"PREFIX\"] = \"INFER\"\n",
        "os.environ[\"HYDRA_FULL_ERROR\"] = \"1\"\n",
        "os.environ[\"USER\"] = \"micro\"\n",
        "\n",
        "!python examples/mms/asr/infer/mms_infer.py --model \"/content/fairseq/models_new/mms1b_fl102.pt\" --lang \"ory\" --audio \"/content/audio_samples/audio_18.wav\"\n"
      ],
      "metadata": {
        "id": "J8N1RKtBiw5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U nltk\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFgM1QGdj8oa",
        "outputId": "f111f2be-d35f-4a3b-ecf1-2b4062c1f971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Tokenize candidate and reference sentences\n",
        "reference = \"ନମସ୍କାର। ଓଡିଶା ସରକାରଙ୍କ ପ୍ରାଣୀ ଚିକିତ୍ସା ଆଉ ପ୍ରାଣୀ ପାଳନ ସୂଚନା ସେବା କୁ ଆପଣଁକୁ ସ୍ଵାଗତ. ଚାଷ ଭାଇ ଓ ଭଉଣୀ ମାନେ ଆସନ୍ତୁ ଗାଈ ଓ ମଇଁଷି ମାନଙ୍କ କ୍ରୋଧାନ୍ବିତ ରୋଗ ର ନିରାକରଣ ବିଷୟ ରେ ଜାଣିବା. ନିୟମିତ ସ୍ବାସ୍ଥ୍ୟ ର ନିରୀକ୍ଷଣ,ଟୀକା କରଣ ଓ କୃମି ନାଶକ ଔଷଧ ର ପ୍ରୟୋଗ, Probiotics ଓ ଯକୃତ ବର୍ଦ୍ଧକ ର ବ୍ୟବହାର,ସଫା ପାଣି ଯୋଗାଇବା, ସୁଷମ ସନ୍ତୁଳିତ ଖାଦ୍ୟ ଇତ୍ୟାଦି ଦେବା, ରୋଷେଇ ପରେ ବଳି ପଡୁଥିବା ଖାଦ୍ୟ ଇତ୍ୟାଦି ନ ଦେବା,ପଶୁ ମାନଙ୍କ ଲାଗି ପ୍ରକୃଷ୍ଟ୍ ଖାଦ୍ୟ ଇତ୍ୟାଦି ଖାଇବାକୁ ଦେବା,ଫିମ୍ପି ଯୁକ୍ତ ଖାଦ୍ୟ ନ ଦେବା ,ଜ୍ବରର ନିରାକରଣ କରିବା ତଥା ସ୍ଥିର ପରିବେଶ ଦେବା ଇତ୍ୟାଦି ଗାଈର ଭୋକ ଓ ପାଚନ ଶକ୍ତି  ନ କମିଯିବା ର ନିରାକରଣ ଅଟେ।\".split()\n",
        "candidate = \"ନମସ୍କାର 2ଡିଶା ସରକାରଙ୍କ ଆମକୃଷି ପ୍ରାଣୀଚିକିତ୍ସାଓ ପ୍ରାଣୀପାଳନ ସୂଚନା ସେବାକୁ ଆପଣଙ୍କୁ ସ୍ୱାଗତ। ଚାସି ବାହି ଓ ଭଣିମାନେ ଆଶନ୍ତୁ ଗାଈ ଓ ମଏସିମାନଙ୍କ କ୍ଷୁଧାହୀନତା ରୋଗର ନିରାକରଣ ବିଷୟରେ ଜାଣିବା ନିୟମିତ ସ୍ୱାସ୍ଥ୍ୟର ନିରୀକ୍ଷଣ ଟୀକାକରଣ ଓ କ୍ରମିନାସକ ଔଷଧର ପ୍ରୟୋଗ ପ୍ରୋବାୟୋଟିକ୍ସ ଓ ଯକୃତ ବର୍ଦ୍ଧକର ବ୍ୟବହାର ସଫାପାଣି ଯୋଗେଇବା ସୁଶମ ସନ୍ତୁଳିତ ଖାଦ୍ୟ ଇତ୍ୟାଦି ଦେବା ଋୋଷଇ ପରେ ବଳି ପଡ଼ୁଥିବା ଖାଦ୍ୟ ଇତ୍ୟାଦି ନ ଦେବା ପଶୁ ମାନଙ୍କ ଲାଗି ପ୍ରକୃଷ୍ଟ ଖାଦ୍ୟ ଇତ୍ୟାଦି ଖାଇବାକୁ ଦେବା ଫିମ୍ପିଯୁକ୍ତ ଖାଦ୍ୟ ନ ଦେବା ଜ୍ୱରର ନିରାକରଣ କରିବା ତଥା ସ୍ଥିର ପରିବେଶ ଦେବା ଇତ୍ୟାଦି ଗାଈର ଭୋକ ଓ ପାଚନ ଶକ୍ତି ନକମିଯିବାର ନିରାକରଣ ଅଟେ। ଏହି କୃଷୀ ସୂଚନା ଉପରେ ଅଧିକ ଜାଣିବା ପାଇଁ କିମ୍ବା କୃଷି ପଶୁ ପାଳନ ଓ ମଥ୍ୟଚାଷ ଉପରେ ଯେକୌଣସି ପ୍ରଶ୍ନ ପଚାରିବା ପାଇଁ ଆମ କୃଷୀର ନିଶୁଳ୍କ ନମ୍ବର 1155333 କୁ କଲ୍ କରନ୍ତୁ ଧନ୍ୟବାଦ।\".split()\n",
        "\n",
        "# Calculate BLEU score\n",
        "bleu_score = sentence_bleu([reference], candidate)\n",
        "\n",
        "# Print the BLEU score\n",
        "print(\"BLEU Score:\", bleu_score)\n"
      ],
      "metadata": {
        "id": "xSFvZowrS5b-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7074aa12-ecea-44a0-8e65-3e8ad2f3e9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.18066180177560492\n"
          ]
        }
      ]
    }
  ]
}