{
  "models": [
    {
      "serviceName": "token_counter_openai",
      "modelBasePath": "src/token_counter/openai/local/.",
      "apiBasePath": "token_counter/openai/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "build": true
    }, 
    {
      "serviceName": "asr_whisper_en",
      "modelBasePath": "src/asr/whisper_en/local/.",
      "apiBasePath": "asr/whisper_en/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": ["client_max_body_size 100M;", "proxy_read_timeout 600;", "proxy_connect_timeout 600;", "proxy_send_timeout 600;"],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    }, 
     {
      "serviceName": "asr_lang_detect",
      "modelBasePath": "src/asr/whisper_lang_rec/local/.",
      "apiBasePath": "asr/whisper_lang_rec/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": ["client_max_body_size 100M;", "proxy_read_timeout 600;", "proxy_connect_timeout 600;", "proxy_send_timeout 600;"],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },    
        {
      "serviceName": "ner",
      "modelBasePath": "src/ner/agri_ner_akai/local/.",
      "apiBasePath": "ner/agri_ner_akai/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "build": false
    },    
        {
      "serviceName": "word_score",
      "modelBasePath": "src/search/word_score/local/.",
      "apiBasePath": "/search/word_score/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "build": false
    },
    {
      "serviceName": "spell_check",
      "modelBasePath": "src/spell_check/kenlm/local/.",
      "apiBasePath": "spell_check/kenlm/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "build": false
    },
    {
      "serviceName": "flow_classification",
      "modelBasePath": "src/text_classification/flow_classification/local/.",
      "apiBasePath": "text_classification/flow_classification/local/",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "constraints": ["node.role==worker"],
      "build": false
    },
    {
      "serviceName": "text_translation_azure_dict",
      "modelBasePath": "src/text_translation/azure_dict/remote/.",
      "apiBasePath": "/text_translation/azure_dict/remote",
      "containerPort": 8000,
      "environment": {
        "AZURE_TRANSLATE_KEY": "${AZURE_TRANSLATE_KEY}"
      },
      "nginx": [],
      "build": false
    },
    {
      "serviceName": "dict_aug_generate_sent",
      "modelBasePath": "src/data_generation/dictionary_aug/remote/.",
      "apiBasePath": "data_generation/dictionary_aug/remote/",
      "containerPort": 8000,
      "environment": {
        "OPENAI_API_KEY": "${OPENAI_API_KEY}"
      },
      "nginx": [],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },   
    {
      "serviceName": "text_translation_azure",
      "modelBasePath": "src/text_translation/azure/remote/.",
      "apiBasePath": "/text_translation/azure/remote",
      "containerPort": 8000,
      "environment": {
        "AZURE_TRANSLATE_KEY": "${AZURE_TRANSLATE_KEY}"
      },
      "nginx": [],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "asr_mms",
      "modelBasePath": "src/asr/fairseq_mms/local/.",
      "apiBasePath": "/asr/fairseq_mms/local",
      "containerPort": 8000,
      "environment": {},
      "nginx": ["client_max_body_size 100M;", "proxy_read_timeout 600;", "proxy_connect_timeout 600;", "proxy_send_timeout 600;"],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "coref_fcoref",
      "modelBasePath": "src/coref/fcoref/local/.",
      "apiBasePath": "/coref/fcoref/local",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "text_translation_bhashini",
      "modelBasePath": "src/text_translation/bhashini/remote/.",
      "apiBasePath": "/text_translation/bhashini/remote",
      "containerPort": 8000,
      "environment": {},
      "nginx": [],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "text_translation_ai4bharat",
      "modelBasePath": "src/text_translation/ai4bharat/remote/.",
      "apiBasePath": "src/text_translation/ai4bharat/remote",
      "containerPort": 8000,
      "environment": {},
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "text_lang_detection_bhashini",
      "modelBasePath": "src/text_lang_detection/bhashini/remote/.",
      "apiBasePath": "/text_lang_detection/bhashini/remote",
      "containerPort": 8000,
      "environment": {},
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
      },
    {
      "serviceName": "chunking_mpnet",
      "modelBasePath": "src/chunking/MPNet/local/.",
      "apiBasePath": "chunking/MPNet/local",
      "containerPort": 8000,
      "environment": {
        "OPENAI_API_KEY": "${OPENAI_API_KEY}"
      },
      "nginx": ["client_max_body_size 100M;", "proxy_read_timeout 600;", "proxy_connect_timeout 600;", "proxy_send_timeout 600;"],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "embedding_instructor",
      "modelBasePath": "src/embeddings/instructor/local/.",
      "apiBasePath": "/embeddings/instructor/local",
      "containerPort": 8000,
      "environment": {
        "OPENAI_API_KEY": "${OPENAI_API_KEY}"
      },
      "nginx": ["client_max_body_size 100M;", "proxy_read_timeout 600;", "proxy_connect_timeout 600;", "proxy_send_timeout 600;"],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    },
    {
      "serviceName": "llm_openai_gpt3",
      "modelBasePath": "src/llm/openai/chatgpt3/.",
      "apiBasePath": "/llm/openai/chatgpt3",
      "containerPort": 8000,
      "environment": {
        "OPENAI_API_KEY": "${OPENAI_API_KEY}"
      },
      "nginx": [],
      "constraints": ["node.labels.node_vm_type==gpu"],
      "build": false
    }
  ]
}
